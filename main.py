import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.documents import Document
from langchain_core.vectorstores import InMemoryVectorStore
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from docling.document_converter import DocumentConverter

# ---------- Step 1: Convert Document ----------
source = "data/STROKEbyYear2025.xlsx"
converter = DocumentConverter()
result = converter.convert(source)

# Export to markdown
markdown_text = result.document.export_to_markdown()

# Save to file
with open("dataset.md", "w", encoding="utf-8") as f:
    f.write(markdown_text)

# ---------- Step 2: Load Environment Variables ----------
load_dotenv(".env")

LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET", "YOUR_LINE_CHANNEL_SECRET")
LINE_CHANNEL_ACCESS_TOKEN = os.getenv(
    "LINE_CHANNEL_ACCESS_TOKEN", "YOUR_LINE_ACCESS_TOKEN"
)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ---------- Step 3: Convert Markdown to LangChain Documents ----------
content_list = markdown_text.split("\n")
langchain_documents = [
    Document(page_content=content.strip())
    for content in content_list
    if content.strip()
]

# ---------- Step 4: Create Vector Store ----------
embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
vector_store = InMemoryVectorStore(embeddings)
_ = vector_store.add_documents(langchain_documents)

retriever = vector_store.as_retriever(search_kwargs={"k": 1})
llm = ChatOpenAI(model="gpt-4o-mini")

# ---------- Step 5: Define Prompt Template ----------
template = """‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ ‡∏≠‡∏≤‡∏™‡∏≤‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏™‡∏∏‡∏Ç‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏´‡∏°‡∏π‡πà‡∏ö‡πâ‡∏≤‡∏ô (‡∏≠‡∏™‡∏°.) 
‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÑ‡∏î‡πâ 
‡πÇ‡∏î‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ Field ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ  
hn               -- ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢,
date             -- ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•,
full_name        -- ‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏•‡∏∞‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢,
address          -- ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢,
bmi              -- ‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏°‡∏ß‡∏•‡∏Å‡∏≤‡∏¢ (Body Mass Index),
sbp              -- ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏ô‡πÇ‡∏•‡∏´‡∏¥‡∏ï‡∏ã‡∏¥‡∏™‡πÇ‡∏ï‡∏•‡∏¥‡∏Å (Systolic Blood Pressure),
dbp              -- ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏ô‡πÇ‡∏•‡∏´‡∏¥‡∏ï‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á (Diastolic Blood Pressure),
blood_sugar      -- ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•‡πÉ‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏î,
bone_status      -- ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Ç‡∏≠‡∏á‡∏Å‡∏£‡∏∞‡∏î‡∏π‡∏Å,
dementia         -- ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏™‡∏°‡∏≠‡∏á‡πÄ‡∏™‡∏∑‡πà‡∏≠‡∏°     (0 = ‡πÄ‡∏ó‡πá‡∏à, 1 = ‡∏à‡∏£‡∏¥‡∏á),
depression       -- ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ã‡∏∂‡∏°‡πÄ‡∏®‡∏£‡πâ‡∏≤       (0 = ‡πÄ‡∏ó‡πá‡∏à, 1 = ‡∏à‡∏£‡∏¥‡∏á)
nutrition_status -- ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÇ‡∏†‡∏ä‡∏ô‡∏≤‡∏Å‡∏≤‡∏£,
smoking          -- ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏π‡∏ö‡∏ö‡∏∏‡∏´‡∏£‡∏µ‡πà     (0 = ‡πÄ‡∏ó‡πá‡∏à, 1 = ‡∏à‡∏£‡∏¥‡∏á),
recorder         -- ‡∏ú‡∏π‡πâ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•,

‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÅ‡∏•‡∏∞ ‡∏°‡∏µ emoji ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô
"‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç 123456789 ‡∏ä‡∏∑‡πà‡∏≠ ‡∏ô‡∏≤‡∏¢ ‡∏Å ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏ô‡πÇ‡∏•‡∏´‡∏¥‡∏ï 120/80 mmHg ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•‡πÉ‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏î 100 mg/dL ‡πÅ‡∏•‡∏∞ ‡∏°‡∏µ‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏°‡∏ß‡∏•‡∏Å‡∏≤‡∏¢ 22.5 kg/m¬≤ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î ‡∏ß‡∏±‡∏ô ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡∏õ‡∏µ "
‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö üòä

{context}

Question: {query}
"""

prompt = ChatPromptTemplate.from_template(template)
qa_chain = prompt | llm | StrOutputParser()


# ---------- Step 6: Helper Function ----------
def format_docs(relevant_docs):
    return "\n".join(doc.page_content for doc in relevant_docs)


# ---------- Step 7: Interactive Loop ----------
print("üë©‚Äç‚öïÔ∏è ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞ ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢ ‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå 'exit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å")

while True:
    query = input("‚ùì ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì: ").strip()
    if query.lower() == "exit":
        print("üëã ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ô‡∏∞‡∏Ñ‡∏∞")
        break

    relevant_docs = retriever.invoke(query)
    answer = qa_chain.invoke({"context": format_docs(relevant_docs), "query": query})
    print("üí¨ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:", answer)
